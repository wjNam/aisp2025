<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="UTF-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0" />
	<meta name="author" content="" />
	<meta name="description" content="" />
	<!-- Links -->
	<link href="../css/sp.css" rel="stylesheet" />
	<link href="../css/sanitize.css" rel="stylesheet" />
	<link rel="preconnect" href="https://fonts.googleapis.com" />
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
	<link
		href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,100;0,300;0,400;0,700;0,900;1,100;1,300;1,400;1,700;1,900&display=swap"
		rel="stylesheet" />
	<!-- Tittle -->
	<title>인공지능신호처리 학술대회</title>
	<!-- Font Awesome Icons -->
	<script src="https://kit.fontawesome.com/2f238780d4.js" crossorigin="anonymous"></script>
	<!-- Script -->
	<script src="../index.js" defer></script>
</head>

<body>
	<header>
		<!-- Navigation mobile -->
		<nav class="nav__mobile-menu">
			<button class="nav__btn-mobile" type="button">
				<i class="nav__icon-close fas fa-times"></i>
			</button>
			<ul class="nav__mobile">
				<li class="nav__mobile-list">
					<a class="nav__mobile-links" href="../index.html">홈</a>
				</li>
				<li class="nav__mobile-list">
					<a class="nav__mobile-links" href="./organizer.html">위원회</a>
				</li>
				<li class="nav__mobile-list">
					<a class="nav__mobile-links" href="./submit.html">논문제출</a>
				</li>
				<li class="nav__mobile-list">
					<a class="nav__mobile-links" href="./sp.html">특별세션</a>
				</li>
				<li class="nav__mobile-list">
					<a class="nav__mobile-links" href="./program.html">프로그램</a>
				</li>
				<li class="nav__mobile-list">
					<a class="nav__mobile-links" href="./reg.html">등록안내</a>
				</li>
				<li class="nav__mobile-list">
					<a class="nav__mobile-links" href="https://tour.daegu.go.kr/index.do">여행안내</a>
				</li>
				<li class="nav__mobile-list">
					<a class="nav__mobile-links" href="./venue.html">오시는 길</a>
				</li>
			</ul>
		</nav>
		<!-- Navigation desktop -->
		<nav>
			<div class="nav__container">
				<!-- <a href="../index.html"><img class="nav__logo" src="../img/fintech-logo-1.svg" alt="FinTech logo" /></a> -->
				<a href="../index.html">
					<div>
						<h3 class="hero__h5"><strong>인공지능신호처리<br>
								학술대회</strong>
						</h3>
					</div>
				</a>
				<div>
				</div>
				<ul class="nav__ul">
					<li><a class="nav__a" href="./organizer.html">위원회</a></li>
					<li><a class="nav__a" href="./submit.html">논문제출</a></li>
					<li><a class="nav__a" href="./sp.html">특별세션</a></li>
					<li><a class="nav__a" href="./program.html">프로그램</a></li>
					<li><a class="nav__a" href="./reg.html">등록안내</a></li>
					<li><a class="nav__a" href="https://tour.daegu.go.kr/index.do">여행안내</a></li>
					<li><a class="nav__a" href="./venue.html">오시는 길</a></li>
				</ul>
			</div>
			<button class="nav__btn-icon" type="button">
				<i class="nav__icon--open fas fa-bars"></i>
			</button>
		</nav>
		<nav class="nav-top">
			<ul class="nav-top__ul">
			</ul>
		</nav>
	</header>
	<main>
		<!-- Hero -->
		<section class="hero-about--img">
			<div class="hero-about__container">
				<div class="hero-about__container-img">
				</div>
				<hgroup class="hero-about__hgroup">
					<h1 class="hero__h1">
						<strong>특별세션</strong>
					</h1>
				</hgroup>
			</div>
		</section>
		<!-- Speakers Info -->
		<section class="logo">
			<div class="logo__container">
				<h3 class="logo__h3">초청강연</h3>
				<div class="logo__decoration">
				</div>
				<ul class="speakers__list">
					<li class="speakers__card">
						<div class="speakers__img-container">
							<img class="speakers__img" src="../img/people/cswon.jpg" alt="Speakers image">
							<hgroup>
								<h3 class="speakers__name">원치선 교수</h3>
								<h4 class="speakers__role">동국대학교</h4>
							</hgroup>
						</div>
						<div class="speakers__info">
							<p class="lecture_title">
								심층 신경망 기반 Audio-Visual 신호 처리
							</p>
							<p class="speakers__description">
								일반적으로 비디오는 영상 정보뿐만이 아니라 오디오 정보를 동반한다. 따라서 오디오와 비디오 정보를 서로 보완적으로 활용함으로써 Audio-Visual 신호
								처리 문제의 성능을 향상시킬 수 있다. 예를 들어, 오디오 신호의 분리를 위해 비디오 정보를 활용할 수 있고, 비디오 정보만을 사용한 동작인식에 비디오와
								동반된 오디오 정보를 활용하여 인식성능을 향상시킬 수 있다. 본 강연에서는 심층 신경망 기반 Audio-Visual 신호 처리 연구의 동향과 최근의 응용
								사례를 소개한다.
							</p>
						</div>
					</li>
					<li class="speakers__card">
						<div class="speakers__img-container">
							<img class="speakers__img" src="../img/people/hjj.jpeg" alt="Speakers image">
							<hgroup>
								<h3 class="speakers__name">한재준 마스터</h3>
								<h4 class="speakers__role">삼성전자 종합기술원</h4>
							</hgroup>
						</div>
						<div class="speakers__info">
							<p class="lecture_title">
								Foundation Model in Industrial Computer Vision Applications
							</p>
							<p class="speakers__description">
								chatGPT 등의 거대 언어 모델이 등장하면서, 다양한 Benchmark에서 인간 수준을 뛰어 넘는 성능을 보여 주고 있으며, 이러한 언어 모델을 접목한 다양한 서비스가 개발되고 있다. Computer Vision 분야에서도 Foundation Model 및 Diffusion Model과 같은 Generative Model 들이 등장하며 언어 기반 영상 생성 등 다양한 응용이 제시되고 있다.
특히 거대 언어 모델은 Chain of Thoughts와 같은 논리적 추론 능력 언어모델을 학습하면서 발생하게 된다. 이러한 거대 언어 모델에서 발현되는 지능과 Computer Vision 기술 측면에서 언어 모델이 가지는 의미와 활용에 대하여 논의하고자 한다.
							</p>
						</div>
					</li>
					<li class="speakers__card">
						<div class="speakers__img-container">
							<img class="speakers__img" src="../img/people/yhj.jpg" alt="Speakers image">
							<hgroup>
								<h3 class="speakers__name">윤형진 기술고문</h3>
								<h4 class="speakers__role">인피니언 코리아</h4>
							</hgroup>
						</div>
						<div class="speakers__info">
							<p class="lecture_title">
								Practitioner’s View on Signal Processing and Machine Learning Approach
							</p>
							<p class="speakers__description">
								인공지능을 응용한 서비스와 제품은 갑자기 우리 생활 곳곳에서 그 모습을 드러내고 있고, 많은 사람들이 여기에 자극을 받아 현업에 인공지능을 활용할 수 있는
								방안을 모색하고 있다. 고전적인 신호처리에 의해 충실하게 그 역할을 수행하던 것들도 이러한 흐름에 따라 인공지능으로 대체하려는 시도가 활발하지만 그 목적과
								효과에 대해서는 눈을 닫는 경우도 볼 수 있다.
								문자 그대로 인공지능은 사람이 정해준 목표를 충실하게 이행하는 것이므로, 인공지능의 적용 범위와 그 성능 목표치를 정하고, 그것을 어떻게 평가하고 달성할
								것인가를 정하는 것은 사람의 몫이다. 또한 문제를 식별하고 분석하는 과정에서 고전적인 신호처리는 여전히 사람에게 직관과 통찰을 제공하는 훌륭한 도구이다. 본
								강연에서는 실무 사례를 중심으로 신호처리와 인공지능의 조화를 통해 더욱 효과적으로 현업에 적용하기 위한 방안을 함께 모색하고자 한다.
							</p>
						</div>
					</li>
				</ul>
			</div>
		</section>
		<section class="logo">
			<div class="logo__container">
				<h3 class="logo__h3">튜토리얼</h3>
				<div class="logo__decoration">
				</div>
				<ul class="speakers__list">
					<li class="speakers__card">
						<div class="speakers__img-container">
							<img class="speakers__img" src="../img/people/srk.png" alt="Speakers image">
							<hgroup>
								<h3 class="speakers__name">김승룡 교수</h3>
								<h4 class="speakers__role">고려대학교</h4>
							</hgroup>
						</div>
						<div class="speakers__info">
							<p class="lecture_title">
								Towards View-Consistent Text-to-3D Generation
							</p>
							<p class="speakers__description">
								Text를 입력으로 받아 3차원 모델을 만드는 기술은 최근에 Diffusion Model과 Neural Radiance Fields (NeRF)의 성공에
								힘입어 실제적인 적용이 가능한 수준의 결과들이 공개되고 있다. 하지만 이러한 기존의 기술은 2차원 Diffusion Model에만 의존하다보니 생성된 3차원
								모델이 View-inconsistent 한 결과를 자주 보여준다. 본 세미나에서는 이러한 View-inconsistency 문제를 해결하기 위한 연구들을
								소개하고 향후 방향성에 대해서 논의해보고자 한다.
							</p>
						</div>
					</li>
					<li class="speakers__card">
						<div class="speakers__img-container">
							<img class="speakers__img" src="../img/people/shl.jpeg" alt="Speakers image">
							<hgroup>
								<h3 class="speakers__name">임성훈 교수</h3>
								<h4 class="speakers__role">DGIST</h4>
							</hgroup>
						</div>
						<div class="speakers__info">
							<p class="lecture_title">
								Recent Advances in Vision Foundation Models
							</p>
							<p class="speakers__description">
								Visual understanding, such as image classification or object detection, is one of the
								long-standing challenges in computer vision. Until now, most research has been conducted
								using models specialized for each problem, and this approach had limitations in fully
								harnessing potential synergies between various tasks. However, recently, based on the
								success of large-scale visual-language pre-training, there has been increasing interest
								in the 'Vision foundation' model that can be applied to various tasks ranging from the
								image level to the pixel level. In this tutorial, I aim to introduce the latest research
								trends and learning methods for such 'Vision foundation' models.
							</p>
						</div>
					</li>
				</ul>
			</div>
		</section>
		<section class="logo">
			<div class="logo__container">
				<h3 class="logo__h3">우수 신진연구자 수상자</h3>
				<div class="logo__decoration">
				</div>
				<ul class="speakers__list">
					<li class="speakers__card">
						<div class="speakers__img-container">
							<img class="speakers__img" src="../img/people/sic.png" alt="Speakers image">
							<hgroup>
								<h3 class="speakers__name">조성인 교수</h3>
								<h4 class="speakers__role">동국대학교</h4>
							</hgroup>
						</div>
						<div class="speakers__info">
							<p class="lecture_title">
								최신 도메인 적응 기법의 이해
							</p>
							<p class="speakers__description">
								본 강연에서는 소스 도메인에서의 풍부한 레이블 정보를 기반으로, 레이블 정보가 존재하지 않거나, 충분하지 않은 목표 도메인에서의 우수한 성능을 제공하기 위한
								모델 훈련 기법인 도메인 적응 기법을 소개한다. 구체적으로, 목표 도메인의 일부 레이블 정보의 활용 가용 여부에 따라서, 도메인 적응 기법을 비지도 도메인
								적응 기법과 준지도 도메인 적응 기법으로 분류하여 설명한다.
							</p>
						</div>
					</li>
				</ul>
			</div>
		</section>
		<section class="logo">
			<div class="logo__container">
				<h3 class="logo__h3">신진연구자 세션</h3>
				<div class="logo__decoration">
				</div>
				<ul class="speakers__list">
					<li class="speakers__card">
						<div class="speakers__img-container">
							<img class="speakers__img" src="../img/people/sjl.jpeg" alt="Speakers image">
							<hgroup>
								<h3 class="speakers__name">이석주 교수</h3>
								<h4 class="speakers__role">한국에너지공과대학교</h4>
							</hgroup>
						</div>
						<div class="speakers__info">
							<p class="lecture_title">
								사전지식을 활용한 자율주행 시각 인지 기법
							</p>
							<p class="speakers__description">
								자율주행 기술은 시각적 인지 능력에 의존한다. 이러한 시각 인지는 목적에 따라 크게 의미론적 인지와 기하학적 인지로 분류된다. 이때, 각각의 태스크를 처리하는
								신경망들은 특정한 하나의 작업을 수행하는 데 유용하지만, 이들의 추론 정보들을 서로 유기적으로 활용한다면 더 높은 강인성을 확보할 수 있다. 본 강연에서는
								서로 다른 태스크에서 생성된 정보를 사전지식으로 학습에 활용하여 본 태스크의 인식 성능을 개선하는 기법들을 소개한다.
							</p>
						</div>
					</li>
					<li class="speakers__card">
						<div class="speakers__img-container">
							<img class="speakers__img" src="../img/people/hnk.jpeg" alt="Speakers image">
							<hgroup>
								<h3 class="speakers__name">김한울 교수</h3>
								<h4 class="speakers__role">서울과학기술대학교</h4>
							</hgroup>
						</div>
						<div class="speakers__info">
							<p class="lecture_title">
								Monocular 3D Pose and Shape Reconstrcution with Bi-Contextual Attention Module and
								Attention-Guided Modeling
							</p>
							<p class="speakers__description">
								카메라 센서로 취득한 영상에서 주변 객체의 3차원 포즈와 형태를 인지하는 것은 자율 주행에 있어 필수적인 기술로, 최근 컴퓨터 비전 분야에서 활발히 연구가
								진행되고 있다. 본 강연에서는 3차원 포즈와 형태 추정의 기본 개념을 소개하고, 주행 환경에서 고려할 수 있는 문맥 정보에 대해 논의한다. 또한 이러한 시맨틱
								정보를 활용하여 3차원 포즈 추정의 성능을 개선할 수 있도록 설계된 Bi-Contextual Attention 기법과 형태 추정을 위한
								Attention-Guided Modeling 기법을 살펴본다.
							</p>
						</div>
					</li>
					<li class="speakers__card">
						<div class="speakers__img-container">
							<img class="speakers__img" src="../img/people/jtl.jpeg" alt="Speakers image">
							<hgroup>
								<h3 class="speakers__name">이종택 교수</h3>
								<h4 class="speakers__role">경북대학교</h4>
							</hgroup>
						</div>
						<div class="speakers__info">
							<p class="lecture_title">
								Augmenting Vision-based Passenger Weight Prediction via Viscoelastic Mat
							</p>
							<p class="speakers__description">
								항공 여행 시, 항공사는 승객의 체중을 측정하기 어렵기 때문에 불필요하게 많은 연료를 싫게 되어 연료 효율이 나빠진다. 일반적인 체중 측정 방법은 붐비는
								공항에서 실용적이지 않기에, 본 강연에서는 새로운 비전 기반의 체중 추론 시스템을 소개한다. 이 시스템은 승객이 걸어가는 동안 매트의 변형 형상을 인식하여
								체중을 추정하는 방식으로, 추가적인 측정 시간 없이 개인의 체중을 정확하게 추정할 수 있다.
							</p>
						</div>
					</li>
					<li class="speakers__card">
						<div class="speakers__img-container">
							<img class="speakers__img" src="../img/people/jsp.jpeg" alt="Speakers image">
							<hgroup>
								<h3 class="speakers__name">박진선 교수</h3>
								<h4 class="speakers__role">부산대학교</h4>
							</hgroup>
						</div>
						<div class="speakers__info">
							<p class="lecture_title">
								환경 변화에 강인한 멀티모달 센서 융합 기반의 3D Vision
							</p>
							<p class="speakers__description">
								최근 자율주행 자동차 등의 다양한 실세계 플랫폼이 상용화되었다. 이러한 플랫폼에서는 외부 환경 변화에 강인한 인식 기술이 필요하다. 이를 위해 환경 변화에
								따른 다양한 센서의 특성이 다르므로, 멀티 모달 센서 정보를 융합하여 환경 변화에 강인한 시각적 인식을 목표로 하고자 하며, 이와 관련된 멀티 모달 센서 융합
								기반의 3차원 정보(Depth) 추정 기법을 소개한다.
							</p>
						</div>
					</li>
					<li class="speakers__card">
						<div class="speakers__img-container">
							<img class="speakers__img" src="../img/people/json.jpeg" alt="Speakers image">
							<hgroup>
								<h3 class="speakers__name">손진희 교수</h3>
								<h4 class="speakers__role">GIST</h4>
							</hgroup>
						</div>
						<div class="speakers__info">
							<p class="lecture_title">
								Zero-shot Referring Image Segmentation with Global-local Context Features
							</p>
							<p class="speakers__description">
								In this talk, I will introduce a new method to find segmentation masks described by text
								expressions in images using zero-shot transfer of CLIP (Contrastive Language-Image
								Pretraining). This method utilizes the image and text encoding capabilities of CLIP to
								capture local and global context for both modalities and identify the target mask in
								unseen datasets without the need for any additional training. The proposed method
								surpasses not only various baselines but also the performance of an existing weakly
								supervised method, and it also outperforms existing supervised models in few-shot
								scenarios.
							</p>
						</div>
					</li>
					<li class="speakers__card">
						<div class="speakers__img-container">
							<img class="speakers__img" src="../img/people/sml.png" alt="Speakers image">
							<hgroup>
								<h3 class="speakers__name">이수목 교수</h3>
								<h4 class="speakers__role">아주대학교</h4>
							</hgroup>
						</div>
						<div class="speakers__info">
							<p class="lecture_title">
								자율주행 3D 객체 인식의 기술적 이슈 및 응용
							</p>
							<p class="speakers__description">
								최근 이미지를 이용한 딥러닝 기법을 통해 높은 물체 인식률의 달성이 가능해졌다. 하지만, 자율주행의 안정적인 인식을 위해서는, 아직 많은 완전자율주행 운영팀이
								비교적 거리정확도가 확실한 3D Point cloud 데이터 기반의 주행에 의존하는 경향이 있다. 3D point cloud 데이터 기반의 물체검출 및 학습
								알고리즘이 필요한 상황에서 데이터의 특성들이 기존 딥러닝과는 다르기 때문에 생기는 기술적인 이슈에 대해서 논의한다. 본 강연에서는 최대한 3D 정보를 손실하지
								않으면서 기존 딥러닝 네트워크를 이용하는 부분에 대한 소개와 응용 방법에 대해서 소개한다.
							</p>
						</div>
					</li>
				</ul>
			</div>
		</section>
		<!-- Footer -->
		<div style="border-top: 2px solid #e9e9e9;">
		</div>
		<!-- Footer -->
		<div style="border-top: 2px solid #e9e9e9;">
		</div>
		<footer>
			<div class="footer__container">
				<address class="footer__address">
					<!-- <a href="https://www.theieie.org/"><img class="footer__img" src="img/ieie_logo.png" alt="ieie logo" /></a> -->
					<p class="footer__p">
						(우 : 06130) 서울특별시 강남구 테헤란로7길 22 <br class=" break-t">
						(역삼동, 과학기술회관 1관 907호)
					</p>
					<p class="footer__p">
						TEL. 02-553-0255~7 <span class="footer__divline"></span>
						FAX. 02-552-6093 <span class="footer__divline"></span>
					</p>
				</address>
			</div>
		</footer>
</body>

</html>
